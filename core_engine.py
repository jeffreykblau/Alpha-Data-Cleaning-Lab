# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
import sqlite3

class AlphaCoreEngine:
    def __init__(self, conn, rules, market_abbr):
        self.conn = conn
        self.rules = rules
        self.market_abbr = market_abbr.upper()
        self.df = None

    def execute(self):
        print(f"--- ğŸš€ å•Ÿå‹• {self.market_abbr} æ•¸æ“šç²¾ç…‰ ---")
        
        # 1. è®€å–åŸå§‹æ•¸æ“š (ç¢ºä¿å¾ 2023 é–‹å§‹ï¼Œè³‡æ–™åº«æ›´ç²¾ç°¡)
        query = """
            SELECT date as æ—¥æœŸ, symbol as StockID, open as é–‹ç›¤, 
                   high as æœ€é«˜, low as æœ€ä½, close as æ”¶ç›¤, volume as æˆäº¤é‡
            FROM stock_prices 
            WHERE date >= '2023-01-01'
        """
        try:
            self.df = pd.read_sql(query, self.conn)
            if self.df.empty:
                return f"Error: {self.market_abbr} No raw data found"
        except Exception as e:
            return f"Error: {e}"

        print(f"ğŸ“Š è®€å…¥åŸå§‹æ•¸æ“šé‡: {len(self.df)} ç­†ã€‚")

        # 2. åŸºç¤é è™•ç†
        self.df = self.df.sort_values(['StockID', 'æ—¥æœŸ']).reset_index(drop=True)
        self.df['æ—¥æœŸ'] = pd.to_datetime(self.df['æ—¥æœŸ'])
        
        # 3. æ•´åˆå¸‚å ´åˆ¥è³‡è¨Š
        try:
            info_df = pd.read_sql("SELECT symbol as StockID, market as MarketType FROM stock_info", self.conn)
            self.df = pd.merge(self.df, info_df, on='StockID', how='left')
        except:
            self.df['MarketType'] = 'Unknown'

        # 4. å¥—ç”¨åŸºç¤å¸‚å ´è¦å‰‡ (ç”±å„åœ‹ Rules ç‰©ä»¶å®šç¾©)
        # å³ä½¿ rules æ²’æŠ“åˆ°ï¼Œå¾ŒçºŒçš„ global åµæ¸¬ä¹Ÿæœƒè£œå¼·
        self.df = self.rules.apply(self.df)
        
        # 5. ğŸ’¡ å…¨çƒå¼·å‹¢æ¨™è¨˜é‚è¼¯ (å–ä»£åŸæœ¬çš„å°ç£å°ˆå±¬é‚è¼¯)
        self._apply_global_strong_event_detection()

        # 6. è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
        self.calculate_returns()
        self.calculate_rolling_returns()
        self.calculate_period_returns()
        self.calculate_sequence_counts()
        self.calculate_risk_metrics_extended()
        
        # 7. æ ¼å¼åŒ–è¼¸å‡º
        self.df['æ—¥æœŸ'] = self.df['æ—¥æœŸ'].dt.strftime('%Y-%m-%d %H:%M:%S')
        
        # 8. å¯«å…¥è³‡æ–™åº« (åŠ å·¥è¡¨ cleaned_daily_base)
        print(f"ğŸ’¾ æ­£åœ¨æ›´æ–°åŠ å·¥è¡¨ cleaned_daily_base...")
        self.df.to_sql("cleaned_daily_base", self.conn, if_exists="replace", index=False)
        
        # 9. å„ªåŒ–è³‡æ–™åº«ç´¢å¼•
        try:
            self.conn.execute("CREATE INDEX IF NOT EXISTS idx_stock_date ON cleaned_daily_base (StockID, æ—¥æœŸ)")
            self.conn.execute("VACUUM")
        except:
            pass
        
        return f"âœ… {self.market_abbr} ç²¾ç…‰å®Œæˆï¼"

    def _apply_global_strong_event_detection(self):
        """ 
        å…¨çƒå¼·å‹¢è‚¡åµæ¸¬è£œå¼·ï¼š
        ä¸è«–å“ªåœ‹å¸‚å ´ï¼Œåªè¦æ¼²å¹… > 10% æˆ–ç¬¦åˆç‰¹å®šå¼·å‹¢æ¢ä»¶ï¼Œçš†æ¨™è¨»ç‚º is_limit_up = 1
        """
        # è¨ˆç®—æ¼²å¹…èˆ‡æ—¥å…§å¯¦é«”
        prev_close = self.df.groupby('StockID')['æ”¶ç›¤'].shift(1)
        ret_vs_prev = (self.df['æ”¶ç›¤'] / prev_close) - 1
        ret_intraday = (self.df['æ”¶ç›¤'] / self.df['é–‹ç›¤']) - 1 

        # --- å®šç¾©åˆ¤å®šé–€æª» ---
        
        # 1. é€šç”¨é–€æª»ï¼šæ¼²å¹… >= 9.8% (åŒ…å«å°/é™¸æ¼²åœã€ç¾/éŸ“å¤§æ¼²)
        is_high_return = (ret_vs_prev >= 0.098)
        
        # 2. å¯¦é«”ç´…æ£’é–€æª»ï¼šç•¶æ—¥é–‹ç›¤åˆ°æ”¶ç›¤æ¼²å¹… >= 9.8% (é‡å°ç„¡æ¼²å¹…é™åˆ¶å¸‚å ´ï¼Œæ•æ‰ç›¤ä¸­å™´ç™¼)
        is_solid_red = (ret_intraday >= 0.098)

        # 3. æ—¥æœ¬(JP)ç‰¹åŒ–ï¼šæ¼²å¹… >= 8% ä¸”æ”¶åœ¨ç•¶æ—¥æœ€é«˜ (æ•æ‰éšæ¢¯å¼æ¼²åœé–æ­»)
        is_jp_limit = (self.market_abbr == "JP") & (ret_vs_prev >= 0.08) & (self.df['æ”¶ç›¤'] == self.df['æœ€é«˜'])

        # ç¶œåˆåˆ¤å®š
        strong_condition = is_high_return | is_solid_red | is_jp_limit
        
        # åŸ·è¡Œæ›´æ–°
        self.df.loc[strong_condition, 'is_limit_up'] = 1
        
        # æ—¥èªŒçµ±è¨ˆ
        count = self.df[strong_condition].shape[0]
        print(f"ğŸ“Š {self.market_abbr} å¼·å‹¢åµæ¸¬ï¼šå·²æ¨™è¨» {count} ç­†å¼·å‹¢äº‹ä»¶ (æ¼²å¹… > 10% æˆ–ç‰¹åŒ–è¦å‰‡)ã€‚")

    def calculate_returns(self):
        self.df['Prev_Close'] = self.df.groupby('StockID')['æ”¶ç›¤'].shift(1)
        self.df['Ret_Day'] = (self.df['æ”¶ç›¤'] / self.df['Prev_Close']) - 1
        self.df['Overnight_Alpha'] = (self.df['é–‹ç›¤'] / self.df['Prev_Close']) - 1
        self.df['Ret_High'] = (self.df['æœ€é«˜'] / self.df['Prev_Close']) - 1
        
    def calculate_rolling_returns(self):
        for d in [5, 20, 200]:
            # ä¿®æ­£ transform å¯«æ³•ç¢ºä¿ç©©å®š
            self.df[f'Ret_{d}D'] = self.df.groupby('StockID')['æ”¶ç›¤'].transform(lambda x: x / x.shift(d) - 1)

    def calculate_period_returns(self):
        temp_dt = pd.to_datetime(self.df['æ—¥æœŸ'])
        for p, label in [('W', 'å‘¨'), ('M', 'æœˆ')]:
            # ä½¿ç”¨ temp_dt é¿å…ä¿®æ”¹åŸå§‹ dataframe æ ¼å¼
            first = self.df.groupby(['StockID', temp_dt.dt.to_period(p)])['æ”¶ç›¤'].transform('first')
            self.df[f'{label}ç´¯è®¡æ¼²è·Œå¹…'] = (self.df['æ”¶ç›¤'] / first) - 1

    def calculate_sequence_counts(self):
        """ ä¿®æ­£é€£æ¼²/é€£è·Œè¨ˆæ•¸é‚è¼¯ """
        def get_sequence(series):
            # åªè¦ series ä¸ç‚º 0 ä¸”é€£çºŒï¼Œå°±é–‹å§‹è¨ˆæ•¸
            blocks = (series != series.shift()).cumsum()
            return series * (series.groupby(blocks).cumcount() + 1)
        
        # Seq_LU_Count ä»£è¡¨ã€Œé€£çºŒå¼·å‹¢/æ¼²åœå¤©æ•¸ã€
        self.df['Seq_LU_Count'] = self.df.groupby('StockID')['is_limit_up'].transform(get_sequence)

    def calculate_risk_metrics_extended(self):
        for d in [10, 20]:
            self.df[f'volatility_{d}d'] = self.df.groupby('StockID')['Ret_Day'].transform(
                lambda x: x.rolling(d).std() * (252**0.5)
            )
