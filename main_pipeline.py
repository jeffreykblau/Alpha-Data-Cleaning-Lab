import os
import sqlite3
import pandas as pd
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload
from google.oauth2.service_account import Credentials
import io
import json

# å°å…¥è‡ªå®šç¾©æ¨¡çµ„
from market_rules import MarketRuleRouter
from core_engine import AlphaCoreEngine

class AlphaDataPipeline:
    def __init__(self, market_abbr):
        # ä¾‹å¦‚å‚³å…¥ "TW"ï¼Œå‰‡è½‰æ›ç‚ºå¤§å¯«
        self.market_abbr = market_abbr.upper()
        # è‡ªå‹•ç”Ÿæˆçš„è³‡æ–™åº«æª”åï¼šä¾‹å¦‚ tw_stock_warehouse.db
        self.db_name = f"{self.market_abbr.lower()}_stock_warehouse.db"
        self.creds = self._load_credentials()
        self.service = build('drive', 'v3', credentials=self.creds)

    def _load_credentials(self):
        creds_json = os.environ.get("GDRIVE_SERVICE_ACCOUNT")
        if not creds_json:
            raise ValueError("âŒ æ‰¾ä¸åˆ°ç’°å¢ƒè®Šæ•¸: GDRIVE_SERVICE_ACCOUNT")
        return Credentials.from_service_account_info(json.loads(creds_json))

    def find_file_id_by_name(self, filename):
        """
        ğŸš€ é€éæª”ååœ¨ Google Drive æœå°‹æª”æ¡ˆ ID
        """
        query = f"name = '{filename}' and trashed = false"
        results = self.service.files().list(q=query, fields="files(id, name)").execute()
        files = results.get('files', [])
        if not files:
            raise ValueError(f"âŒ åœ¨é›²ç«¯æ‰¾ä¸åˆ°æª”æ¡ˆ: {filename}")
        return files[0]['id']

    def download_db(self):
        file_id = self.find_file_id_by_name(self.db_name)
        print(f"ğŸ“¥ åµæ¸¬åˆ°é›²ç«¯æª”æ¡ˆ ID: {file_id}ï¼Œé–‹å§‹ä¸‹è¼‰...")
        request = self.service.files().get_media(fileId=file_id)
        fh = io.FileIO(self.db_name, 'wb')
        downloader = MediaIoBaseDownload(fh, request)
        done = False
        while not done:
            status, done = downloader.next_chunk()
        print(f"âœ… {self.db_name} ä¸‹è¼‰æˆåŠŸ")

    def _ensure_schema_upgraded(self, conn):
        """
        ğŸš€ ç¢ºä¿è³‡æ–™åº« Schema åŒ…å«ç‚¸æ¿åˆ†ææ‰€éœ€çš„æ¬„ä½ (Ret_High)
        """
        cursor = conn.cursor()
        cursor.execute("PRAGMA table_info(cleaned_daily_base)")
        columns = [column[1] for column in cursor.fetchall()]
        
        # å¦‚æœæ²’æœ‰ Ret_High æ¬„ä½ï¼Œå‰‡æ–°å¢ (é€™èƒ½è§£æ±º Deep_Scan.py å ±éŒ¯å•é¡Œ)
        if 'Ret_High' not in columns:
            print(f"ğŸ› ï¸  æ­£åœ¨ç‚º {self.market_abbr} è³‡æ–™åº«æ–°å¢ Ret_High æ¬„ä½...")
            try:
                cursor.execute("ALTER TABLE cleaned_daily_base ADD COLUMN Ret_High REAL")
                conn.commit()
                print("âœ… æ¬„ä½æ–°å¢æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ æ¬„ä½æ–°å¢ç•°å¸¸ (å¯èƒ½å·²å­˜åœ¨): {e}")

    def upload_db(self):
        file_id = self.find_file_id_by_name(self.db_name)
        # ğŸš€ ä½¿ç”¨ Resumable æŠ€è¡“è™•ç†å¤§æª”æ¡ˆä¸Šå‚³ (è§£æ±ºç¾åœ‹å¸‚å ´ Timeout å•é¡Œ)
        media = MediaFileUpload(self.db_name, mimetype='application/octet-stream', resumable=True)
        request = self.service.files().update(fileId=file_id, media_body=media)
        
        print(f"ğŸ“¤ æ­£åœ¨åŒæ­¥å›é›²ç«¯ (å¯çºŒå‚³æ¨¡å¼)...")
        response = None
        while response is None:
            status, response = request.next_chunk()
            if status:
                print(f"   > é€²åº¦: {int(status.progress() * 100)}%")
        print(f"âœ… {self.market_abbr} é›²ç«¯åŒæ­¥æˆåŠŸ")

    def run_process(self):
        # 1. ä¸‹è¼‰é›²ç«¯ DB
        self.download_db()
        
        conn = sqlite3.connect(self.db_name)
        try:
            # 2. è‡ªå‹•å‡ç´šè³‡æ–™åº«çµæ§‹ (æ–°å¢ç‚¸æ¿æ¬„ä½)
            self._ensure_schema_upgraded(conn)

            # 3. åŸ·è¡Œæ ¸å¿ƒç²¾ç…‰å¼•æ“ (è¨ˆç®—æŒ‡æ¨™ä¸¦å¡«å…¥ Ret_High)
            rules = MarketRuleRouter.get_rules(self.market_abbr)
            engine = AlphaCoreEngine(conn, rules, self.market_abbr)
            summary_msg = engine.execute()
            
            # é‡è¦ï¼šå…ˆé—œé–‰é€£ç·šï¼Œç¢ºä¿æª”æ¡ˆæœªè¢«é–å®šï¼Œæ‰èƒ½é †åˆ©ä¸Šå‚³
            conn.close()
            
            # 4. åŒæ­¥ä¸Šå‚³å›é›²ç«¯
            self.upload_db()
            
            # 5. ç”Ÿæˆæ‘˜è¦å ±å‘Š (ä¿®æ­£æª”åä»¥ç¬¦åˆ YAML çš„ Artifacts æœå°‹è·¯å¾‘)
            # ä¾‹å¦‚: summary_tw_stock_warehouse.txt
            summary_file = f"summary_{self.db_name.replace('.db', '')}.txt"
            with open(summary_file, "w", encoding="utf-8") as f:
                f.write(str(summary_msg))
            
            print(f"ğŸ“„ æ‘˜è¦å ±å‘Šå·²ç”Ÿæˆ: {summary_file}")
            return summary_msg

        except Exception as e:
            if conn:
                conn.close()
            print(f"âŒ æµç¨‹åŸ·è¡Œå¤±æ•—: {e}")
            raise e

if __name__ == "__main__":
    # å¾ GitHub Actions çš„ç’°å¢ƒè®Šæ•¸ä¸­è®€å–å¸‚å ´ä»£è™Ÿ (ä¾‹å¦‚ TW)
    target_market = os.environ.get("MARKET_TYPE")
    if not target_market:
        print("âŒ éŒ¯èª¤ï¼šæœªè¨­å®š MARKET_TYPE")
        exit(1)
    
    pipeline = AlphaDataPipeline(target_market)
    pipeline.run_process()
