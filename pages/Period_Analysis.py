import streamlit as st
import sqlite3
import pandas as pd
import plotly.express as px
import google.generativeai as genai
import os

# 1. é é¢é…ç½®
st.set_page_config(page_title="é•·å‘¨æœŸèˆ‡æ»¾å‹•æ¼²è·Œåˆ†æ", layout="wide")

# 2. å…±ç”¨å‡½æ•¸ï¼šå–å¾—å¸‚å ´å°ˆå±¬è¶…é€£çµ
def get_market_link(symbol, market):
    if market == "TW":
        return f"https://tw.stock.yahoo.com/quote/{symbol}"
    elif market == "US":
        return f"https://finviz.com/quote.ashx?t={symbol}"
    elif market == "JP":
        return f"https://minkabu.jp/stock/{symbol.split('.')[0]}"
    elif market == "HK":
        return f"http://www.aastocks.com/tc/stocks/analysis/stock-quote.ashx?stockid={symbol.split('.')[0]}"
    else:
        return f"https://www.tradingview.com/symbols/{symbol}"

# 3. è®€å–è³‡æ–™åº«
market_option = st.sidebar.selectbox("ğŸš© é¸æ“‡å¸‚å ´", ("TW", "JP", "CN", "US", "HK", "KR"), key="period_market")
db_map = {"TW":"tw_stock_warehouse.db", "JP":"jp_stock_warehouse.db", "CN":"cn_stock_warehouse.db", 
          "US":"us_stock_warehouse.db", "HK":"hk_stock_warehouse.db", "KR":"kr_stock_warehouse.db"}
target_db = db_map[market_option]

if not os.path.exists(target_db):
    st.error(f"è«‹å…ˆå›åˆ°ä¸»é é¢åŒæ­¥ {market_option} è³‡æ–™åº«")
    st.stop()

conn = sqlite3.connect(target_db)

# 4. æŠ“å–æœ€æ–°æ—¥æœŸçš„çµ±è¨ˆæ•¸æ“š
try:
    query = """
    SELECT StockID, æ—¥æœŸ, Ret_Day, 
           (SELECT name FROM stock_info WHERE symbol = StockID) as Name,
           [å‘¨ç´¯è®¡æ¼²è·Œå¹…(æœ¬å‘¨å¼€ç›˜)] as Ret_W,
           [æœˆç´¯è®¡æ¼²è·Œå¹…(æœ¬æœˆå¼€ç›˜)] as Ret_M,
           [å¹´ç´¯è¨ˆæ¼²è·Œå¹…(æœ¬å¹´å¼€ç›˜)] as Ret_Y,
           Ret_5D, Ret_20D, Ret_200D,
           volatility_20d, drawdown_after_high_20d
    FROM cleaned_daily_base
    WHERE æ—¥æœŸ = (SELECT MAX(æ—¥æœŸ) FROM cleaned_daily_base)
    """
    df = pd.read_sql(query, conn)
    
    st.title(f"ğŸš€ {market_option} é•·å‘¨æœŸå‹•èƒ½å„€è¡¨æ¿")
    st.caption(f"æ•¸æ“šåŸºæº–æ—¥: {df['æ—¥æœŸ'].iloc[0] if not df.empty else 'N/A'}")

    # --- ä¹å®®æ ¼åœ–è¡¨ (3x3) ---
    st.subheader("ğŸ“Š æ»¾å‹•èˆ‡æ—¥æ›†å‘¨æœŸåˆ†å¸ƒ")
    
    metrics = [
        ('Ret_5D', 'æ»¾å‹• 5D'), ('Ret_20D', 'æ»¾å‹• 20D'), ('Ret_200D', 'æ»¾å‹• 200D'),
        ('Ret_W', 'æœ¬å‘¨ (W)'), ('Ret_M', 'æœ¬æœˆ (M)'), ('Ret_Y', 'æœ¬å¹´ (Y)'),
        ('volatility_20d', '20D æ³¢å‹•ç‡'), ('drawdown_after_high_20d', '20D å›æ’¤'), ('Ret_Day', 'ä»Šæ—¥æ¼²è·Œ')
    ]

    rows = [st.columns(3) for _ in range(3)]
    for idx, (col_name, label) in enumerate(metrics):
        with rows[idx//3][idx%3]:
            if col_name in df.columns:
                fig = px.histogram(df, x=col_name, title=f"{label} åˆ†å¸ƒ", 
                                   nbins=50, color_discrete_sequence=['#3366ff'])
                fig.update_layout(margin=dict(l=20, r=20, t=40, b=20), height=250)
                st.plotly_chart(fig, use_container_width=True)

    # --- åˆ†ç®±æ¸…å–® (Binning) ---
    st.divider()
    st.subheader("ğŸ“¦ å¼·å‹¢åˆ†ç®±æ¸…å–® (æœ¬æœˆç´¯è¨ˆ)")
    
    bins = [-float('inf'), -0.1, -0.05, 0, 0.05, 0.1, 0.2, float('inf')]
    labels = ["æ…˜è·Œ(<-10%)", "å›æª”(-10%~-5%)", "å¹³ç›¤(-5%~0%)", "è½‰å¼·(0~5%)", "å¼·å‹¢(5~10%)", "å™´ç™¼(10~20%)", "å¦–è‚¡(>20%)"]
    df['Bin'] = pd.cut(df['Ret_M'], bins=bins, labels=labels)

    bin_tabs = st.tabs(labels[::-1]) # å¾å¼·åˆ°å¼±æ’åˆ—
    for i, label in enumerate(labels[::-1]):
        with bin_tabs[i]:
            subset = df[df['Bin'] == label][['StockID', 'Name', 'Ret_M', 'drawdown_after_high_20d']]
            if not subset.empty:
                subset['é€£çµ'] = subset['StockID'].apply(lambda x: get_market_link(x, market_option))
                st.dataframe(
                    subset.sort_values('Ret_M', ascending=False),
                    column_config={"é€£çµ": st.column_config.LinkColumn("å¤–éƒ¨é€£çµ")},
                    use_container_width=True, hide_index=True
                )
            else:
                st.write("ç›®å‰ç„¡ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨")

    # --- 5. AI é€±æœŸå‹•èƒ½è¨ºæ–· (æ–°å¢åŠŸèƒ½) ---
    st.divider()
    st.subheader("ğŸ¤– å¸‚å ´é€±æœŸå‹•èƒ½ AI è¨ºæ–·")
    st.markdown(f"""
    æœ¬æ¨¡çµ„åˆ†æ **{market_option}** å¸‚å ´çš„æ•´é«”å¥åº·åº¦ã€‚æ‚¨å¯ä»¥ç›´æ¥å•Ÿå‹•å…§å»ºçš„ **Gemini å°ˆå®¶åˆ†æ**ï¼Œ
    æˆ–é»æ“Š **ç”¢ç”Ÿæå•è©** è¤‡è£½åˆ° ChatGPT / Claudeï¼Œé€éä¸åŒ AI æ¨¡å‹çš„é‡åŒ–è¦–è§’é€²è¡Œäº¤å‰æ¯”å°ã€‚
    """)
    
    # æº–å‚™å¸‚å ´åˆ†ä½ˆæ‘˜è¦çµ¦ AI
    bin_summary = df['Bin'].value_counts().to_string()
    avg_ret_5d = df['Ret_5D'].mean() * 100
    avg_ret_20d = df['Ret_20D'].mean() * 100
    
    prompt_text = f"""ä½ æ˜¯ä¸€ä½è³‡æ·±é‡åŒ–åˆ†æå¸«ã€‚è«‹åˆ†æ {market_option} å¸‚å ´ç›®å‰çš„é€±æœŸå‹•èƒ½åˆ†ä½ˆï¼š
å¸‚å ´åˆ†ä½ˆæ‘˜è¦ (æœ¬æœˆç´¯ç©æ¼²è·Œå¹…åˆ†ç®±)ï¼š
{bin_summary}

é¡å¤–æŒ‡æ¨™ï¼š
- æ»¾å‹• 5 æ—¥å¹³å‡æ¼²è·Œå¹…ï¼š{avg_ret_5d:.2f}%
- æ»¾å‹• 20 æ—¥å¹³å‡æ¼²è·Œå¹…ï¼š{avg_ret_20d:.2f}%

è«‹æ ¹æ“šä»¥ä¸Šæ•¸æ“šï¼š
1. åˆ¤æ–·ç›®å‰å¸‚å ´è™•æ–¼ã€Œéç†±ã€ã€ã€Œå¥åº·ã€é‚„æ˜¯ã€Œä½è¿·ã€ç‹€æ…‹ï¼Ÿ
2. é‡å°ã€Œå¦–è‚¡ã€èˆ‡ã€Œå™´ç™¼ã€ç®±é«”å…§çš„å€‹è‚¡ï¼Œçµ¦äºˆç›®å‰çš„é¢¨éšªè©•ä¼°ã€‚
3. çµ¦äºˆçŸ­ä¸­ç·šçš„æ“ä½œå»ºè­°ã€‚""".strip()

    # æŒ‰éˆ•ä½ˆå±€
    btn_col1, btn_col2 = st.columns(2)
    
    with btn_col1:
        run_ai = st.button(f"ğŸš€ å•Ÿå‹• Gemini å¸‚å ´è¨ºæ–·", use_container_width=True)
    
    with btn_col2:
        gen_prompt = st.button(f"ğŸ“‹ ç”¢ç”Ÿæå•è© (è©¢å•å…¶ä»– AI)", use_container_width=True)

    # 1. åŸ·è¡Œ Gemini AI è¨ºæ–·
    if run_ai:
        api_key = st.secrets.get("GEMINI_API_KEY")
        if not api_key:
            st.warning("âš ï¸ è«‹å…ˆåœ¨ Streamlit Secrets ä¸­è¨­å®š GEMINI_API_KEY")
        else:
            try:
                genai.configure(api_key=api_key)
                all_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
                target_model = next((m for m in ['models/gemini-1.5-flash', 'gemini-1.5-flash'] if m in all_models), all_models[0])
                model = genai.GenerativeModel(target_model)
                
                with st.spinner(f"AI æ­£åœ¨è§£æå¸‚å ´å‹•èƒ½ (æ¨¡å‹: {target_model})..."):
                    response = model.generate_content(prompt_text)
                    st.info("### ğŸ¤– å¸‚å ´é€±æœŸå‹•èƒ½ AI è¨ºæ–·å ±å‘Š")
                    st.markdown(response.text)
            except Exception as e:
                st.error(f"AI åˆ†æå¤±æ•—: {e}")

    # 2. é¡¯ç¤ºæå•è©å€å¡Š
    if gen_prompt:
        st.success("âœ… æå•è©å·²ç”Ÿæˆï¼æ‚¨å¯ä»¥è¤‡è£½ä¸‹æ–¹å…§å®¹é€²è¡Œè·¨æ¨¡å‹é©—è­‰ã€‚")
        st.code(prompt_text, language="text")
        st.info("""
        ğŸ’¡ **ç‚ºä»€éº¼è¦è£œæå•è©ï¼Ÿ**
        * **ChatGPT (OpenAI)**ï¼šå°å®è§€ç¶“æ¿Ÿè¶¨å‹¢çš„è§£è®€è¼ƒç‚ºå»£æ³›ï¼Œé©åˆç”¨æ–¼åˆ¤æ–·å¸‚å ´ç‹€æ…‹ã€‚
        * **Claude (Anthropic)**ï¼šåœ¨é¢¨éšªæ§ç®¡èˆ‡åˆ†ç®±æ•¸æ“šçš„é‚è¼¯æ¨ç†ä¸Šè¡¨ç¾æ¥µä½³ï¼Œé©åˆå°‹æ‰¾æ“ä½œå»ºè­°ã€‚
        * **äº¤å‰é©—è­‰**ï¼šè‹¥å¤šå€‹æ¨¡å‹å‡æŒ‡å‡ºå¸‚å ´ã€Œéç†±ã€ï¼Œå‰‡æ‡‰æé«˜è­¦è¦ºå¢åŠ ç¾é‡‘æ¯”ä¾‹ã€‚
        """)

except Exception as e:
    st.error(f"åœ–è¡¨ç”Ÿæˆå¤±æ•—: {e}")
    st.info("è«‹æª¢æŸ¥è³‡æ–™åº«æ¬„ä½æ˜¯å¦åŒ…å« Ret_5D, Ret_20D ç­‰æ»¾å‹•æ•¸æ“šã€‚")

finally:
    conn.close()

# --- 6. åº•éƒ¨å¿«é€Ÿé€£çµ (Footer) ---
st.divider()
st.markdown("### ğŸ”— å¿«é€Ÿè³‡æºé€£çµ")
col_link1, col_link2, col_link3 = st.columns(3)
with col_link1:
    st.page_link("https://vocus.cc/article/694f813afd8978000101e75a", label="âš™ï¸ ç’°å¢ƒèˆ‡ AI è¨­å®šæ•™å­¸", icon="ğŸ› ï¸")
with col_link2:
    st.page_link("https://vocus.cc/article/694f88bdfd89780001042d74", label="ğŸ“– å„€è¡¨æ¿åŠŸèƒ½è©³è§£", icon="ğŸ“Š")
with col_link3:
    st.page_link("https://github.com/grissomlin/Alpha-Data-Cleaning-Lab", label="ğŸ’» GitHub å°ˆæ¡ˆåŸå§‹ç¢¼", icon="ğŸ™")
