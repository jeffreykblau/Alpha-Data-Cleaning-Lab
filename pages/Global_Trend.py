import streamlit as st
import sqlite3
import pandas as pd
import plotly.express as px
import os
import io
import json
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
from google.oauth2.service_account import Credentials
import google.genai as genai

# --- 1. é é¢é…ç½® ---
st.set_page_config(page_title="å…¨çƒå¼·å‹¢è‚¡ç”¢æ¥­é€£å‹•ç›£æ¸¬", layout="wide")

st.title("ğŸŒ å…¨çƒå¼·å‹¢è‚¡ç”¢æ¥­é€£å‹•ç›£æ¸¬")
st.caption("åŒæ­¥è¿½è¹¤å…­å¤§å¸‚å ´æ¼²å¹… > 10% ä¹‹å€‹è‚¡ï¼Œåµæ¸¬å…¨çƒç”¢æ¥­è³‡é‡‘æµå‘")

# --- 2. å¸‚å ´èˆ‡è³‡æ–™åº«è¨­å®š ---
db_config = {
    "TW": "tw_stock_warehouse.db",
    "US": "us_stock_warehouse.db",
    "CN": "cn_stock_warehouse.db",
    "JP": "jp_stock_warehouse.db",
    "HK": "hk_stock_warehouse.db",
    "KR": "kr_stock_warehouse.db"
}

# --- 3. è‡ªå‹•ä¸‹è¼‰é‚è¼¯ ---
def download_missing_dbs():
    creds_json = st.secrets.get("GDRIVE_SERVICE_ACCOUNT")
    if not creds_json:
        st.error("âŒ æ‰¾ä¸åˆ° Google Drive æ†‘è­‰ (GDRIVE_SERVICE_ACCOUNT)")
        return
    
    try:
        creds = Credentials.from_service_account_info(json.loads(creds_json))
        service = build('drive', 'v3', credentials=creds)
        
        for m_abbr, db_file in db_config.items():
            if not os.path.exists(db_file):
                with st.spinner(f"ğŸ“¥ æ­£åœ¨å¾é›²ç«¯åŒæ­¥ {m_abbr} è³‡æ–™åº«..."):
                    query = f"name = '{db_file}' and trashed = false"
                    results = service.files().list(q=query, fields="files(id, name)").execute()
                    files = results.get('files', [])
                    if files:
                        file_id = files[0]['id']
                        request = service.files().get_media(fileId=file_id)
                        fh = io.FileIO(db_file, 'wb')
                        downloader = MediaIoBaseDownload(fh, request)
                        done = False
                        while not done:
                            status, done = downloader.next_chunk()
                        st.sidebar.success(f"âœ… {m_abbr} åŒæ­¥æˆåŠŸ")
                    else:
                        st.sidebar.warning(f"âš ï¸ é›²ç«¯æ‰¾ä¸åˆ° {db_file}")
    except Exception as e:
        st.error(f"ä¸‹è¼‰å¤±æ•—: {e}")

# --- å´é‚Šæ¬„æ§åˆ¶ ---
with st.sidebar:
    st.header("âš™ï¸ æ•¸æ“šç®¡ç†")
    if st.button("ğŸš€ ä¸€éµåŒæ­¥å…­åœ‹è³‡æ–™åº«"):
        download_missing_dbs()
        st.cache_data.clear()
        st.rerun()
    
    st.divider()
    st.write("ğŸ“ æœ¬åœ°æª”æ¡ˆç‹€æ…‹ï¼š")
    available_markets = []
    for m_abbr, db_file in db_config.items():
        ready = os.path.exists(db_file)
        st.write(f"{'ğŸŸ¢' if ready else 'ğŸ”´'} {m_abbr}")
        if ready: available_markets.append(m_abbr)

# --- 4. æ•¸æ“šæŠ“å–é‚è¼¯ ---
@st.cache_data(ttl=600)
def fetch_global_strong_stocks(markets):
    all_list = []
    for m in markets:
        db = db_config[m]
        conn = sqlite3.connect(db)
        try:
            latest = pd.read_sql("SELECT MAX(æ—¥æœŸ) FROM cleaned_daily_base", conn).iloc[0,0]
            query = f"""
            SELECT p.StockID, i.name as Name, i.sector as Sector, p.Ret_Day
            FROM cleaned_daily_base p
            LEFT JOIN stock_info i ON p.StockID = i.symbol
            WHERE p.æ—¥æœŸ = '{latest}' AND p.Ret_Day >= 0.1
            """
            df = pd.read_sql(query, conn)
            df['Market'] = m
            all_list.append(df)
        except:
            pass
        finally:
            conn.close()
    return pd.concat(all_list, ignore_index=True) if all_list else pd.DataFrame()

# --- 5. è¦–è¦ºåŒ–èˆ‡åˆ†æ ---
if available_markets:
    global_df = fetch_global_strong_stocks(available_markets)
    
    if not global_df.empty:
        global_df['Sector'] = global_df['Sector'].fillna('æœªåˆ†é¡/é¦™æ¸¯/èˆˆæ«ƒ')

        col_l, col_r = st.columns([1.2, 1])
        
        with col_l:
            st.subheader("ğŸ“Š è·¨åœ‹å¼·å‹¢ç”¢æ¥­ç†±é»")
            chart_df = global_df.groupby(['Sector', 'Market']).size().reset_index(name='Count')
            fig = px.bar(
                chart_df, x='Count', y='Sector', color='Market', orientation='h',
                title="å…¨çƒå¼·å‹¢å€‹è‚¡ç”¢æ¥­åˆ†ä½ˆ (æ¼²å¹… > 10%)", barmode='stack',
                color_discrete_map={"TW": "#FF4B4B", "US": "#1C83E1", "CN": "#E11C1C", "JP": "#FFFFFF", "HK": "#FFD700", "KR": "#00FFCC"}
            )
            fig.update_layout(yaxis={'categoryorder':'total ascending'}, template="plotly_dark")
            st.plotly_chart(fig, use_container_width=True)

        with col_r:
            st.subheader("ğŸ” ä»Šæ—¥å…¨çƒå¼·å‹¢æ¦œ")
            st.dataframe(
                global_df.sort_values(['Market', 'Ret_Day'], ascending=[True, False]),
                column_config={"Ret_Day": st.column_config.NumberColumn("æ¼²å¹…", format="%.2f%%")},
                use_container_width=True, hide_index=True
            )

        # AI è¶¨å‹¢åˆ†æå€å¡Š
        st.divider()
        st.subheader("ğŸ¤– å…¨çƒç”¢æ¥­è¶¨å‹¢ AI è¨ºæ–·")
        st.markdown("""
        æœ¬æ¨¡çµ„å°‡ä»Šæ—¥å…¨çƒå¼·å‹¢è‚¡çš„çµ±è¨ˆæ•¸æ“šé€äº¤ AIã€‚æ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨å…§å»ºçš„ **Gemini è¨ºæ–·**ï¼Œ
        æˆ–æ˜¯ **ç”¢ç”Ÿæå•è©** è¤‡è£½åˆ° ChatGPT / Claude ç­‰æ¨¡å‹ï¼Œè§€å¯Ÿä¸åŒ AI å°å…¨çƒè³‡é‡‘æµå‘çš„è§£è®€ã€‚
        """)

        # é å…ˆæº–å‚™ AI æå•è©å…§å®¹
        sector_summary = global_df.groupby(['Sector', 'Market']).size().to_string()
        trend_prompt = f"""ä½ æ˜¯ä¸€ä½å®è§€æŠ•è³‡å°ˆå®¶ï¼Œè«‹åˆ†æä»Šæ—¥å…¨çƒæ¼²å¹…è¶…é10%çš„è‚¡ç¥¨åˆ†ä½ˆï¼š
{sector_summary}

1. å“ªäº›ç”¢æ¥­å‡ºç¾è·¨åœ‹è¯å‹•ç¾è±¡ï¼Ÿï¼ˆä¾‹å¦‚ï¼šç¾ã€å°ã€æ—¥åŒæ­¥å¤§æ¼² AI åŠå°é«”ï¼‰
2. é€™äº›ç¾è±¡èƒŒå¾Œçš„å…¨çƒè¶¨å‹¢ç‚ºä½•ï¼Ÿï¼ˆæ”¿ç­–æ¨å‹•ã€æŠ€è¡“çªç ´æˆ–è³‡é‡‘é¿éšªï¼‰
3. çµ¦äºˆå®è§€è§’åº¦çš„é¢¨éšªèˆ‡ä½ˆå±€å»ºè­°ã€‚"""

        # æŒ‰éˆ•ä½ˆå±€
        btn_col1, btn_col2 = st.columns(2)
        
        with btn_col1:
            run_ai = st.button("ğŸš€ å•Ÿå‹• Gemini å…¨çƒè¶¨å‹¢è¨ºæ–·", use_container_width=True)
        
        with btn_col2:
            gen_prompt = st.button("ğŸ“‹ ç”¢ç”Ÿæå•è© (è©¢å•å…¶ä»– AI)", use_container_width=True)

        # 1. åŸ·è¡Œ Gemini AI è¨ºæ–·
        if run_ai:
            api_key = st.secrets.get("GEMINI_API_KEY")
            if not api_key:
                st.warning("âš ï¸ è«‹å…ˆåœ¨ Streamlit Secrets ä¸­è¨­å®š GEMINI_API_KEY")
            else:
                try:
                    genai.configure(api_key=api_key)
                    all_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
                    target_model = next((m for m in ['models/gemini-1.5-flash', 'gemini-1.5-flash'] if m in all_models), all_models[0])
                    model = genai.GenerativeModel(target_model)
                    
                    with st.spinner(f"AI æ­£åœ¨è§£æå…¨çƒæ•¸æ“šæµå‘ (æ¨¡å‹: {target_model})..."):
                        response = model.generate_content(trend_prompt)
                        st.info("### ğŸ¤– Gemini å…¨çƒè¶¨å‹¢åˆ†æå ±å‘Š")
                        st.markdown(response.text)
                except Exception as e:
                    st.error(f"AI åˆ†æå¤±æ•—: {e}")

        # 2. é¡¯ç¤ºæå•è©å€å¡Š
        if gen_prompt:
            st.success("âœ… æå•è©å·²ç”Ÿæˆï¼æ‚¨å¯ä»¥è¤‡è£½ä¸‹æ–¹å…§å®¹é€²è¡Œè·¨æ¨¡å‹é©—è­‰ã€‚")
            st.code(trend_prompt.strip(), language="text")
            st.info("""
            ğŸ’¡ **ç‚ºä»€éº¼è¦ä½¿ç”¨æå•è©äº¤å‰é©—è­‰ï¼Ÿ**
            * **ChatGPT (OpenAI)**ï¼šåœ¨åˆ†æå¸‚å ´æƒ…ç·’èˆ‡æ”¿ç­–è§£è®€ä¸Šæœ‰å¾ˆå¼·çš„é‚è¼¯æ€§ã€‚
            * **Claude (Anthropic)**ï¼šæ“…é•·è™•ç†é•·ç¯‡çµ±è¨ˆæ•¸æ“šä¸¦çµ¦å‡ºæ¢ç†åˆ†æ˜çš„ç”¢æ¥­é¢¨éšªè©•ä¼°ã€‚
            * **Gemini (Google)**ï¼šå…·å‚™å¼·å¤§çš„å³æ™‚è³‡è¨Šè™•ç†èƒ½åŠ›èˆ‡ Google ç”Ÿæ…‹ç³»çš„æ•¸æ“šæ´å¯Ÿã€‚
            """)

    else:
        st.warning("ä»Šæ—¥å„åœ‹æš«ç„¡æ¼²å¹… > 10% çš„è‚¡ç¥¨æ•¸æ“šã€‚")
else:
    st.error("è«‹åœ¨å´é‚Šæ¬„é»æ“Šã€Œä¸€éµåŒæ­¥å…­åœ‹è³‡æ–™åº«ã€ä»¥è¼‰å…¥æ•¸æ“šã€‚")

# --- 6. åº•éƒ¨å¿«é€Ÿé€£çµ (Footer) ---
st.divider()
st.markdown("### ğŸ”— å¿«é€Ÿè³‡æºé€£çµ")
col_link1, col_link2, col_link3 = st.columns(3)
with col_link1:
    st.page_link("https://vocus.cc/article/694f813afd8978000101e75a", label="âš™ï¸ ç’°å¢ƒèˆ‡ AI è¨­å®šæ•™å­¸", icon="ğŸ› ï¸")
with col_link2:
    st.page_link("https://vocus.cc/article/694f88bdfd89780001042d74", label="ğŸ“– å„€è¡¨æ¿åŠŸèƒ½è©³è§£", icon="ğŸ“Š")
with col_link3:
    st.page_link("https://github.com/grissomlin/Alpha-Data-Cleaning-Lab", label="ğŸ’» GitHub å°ˆæ¡ˆåŸå§‹ç¢¼", icon="ğŸ™")
